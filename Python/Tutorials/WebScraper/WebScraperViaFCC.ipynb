{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "774c9b97-3bdc-42bb-8998-b40181d14229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<a href=\"/intl/en/about.html\">About Google</a>\n",
      "/intl/en/about.html\n"
     ]
    }
   ],
   "source": [
    "#Name: Abel\n",
    "#Date Started: 2021.07.14\n",
    "#OVERALL PURPOSE: to introduce beautifulsoup and requests to scrape data off websites\n",
    "#Purpose: (Tutorial) To import only links with \"About\" from google.com\n",
    "#Source/Credits: freeCodeCamp.org - https://www.youtube.com/watch?v=87Gx3U0BDlo\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#import pandas as pd\n",
    "import requests\n",
    "\n",
    "result = requests.get(\"https://www.google.com/\")\n",
    "print (result.status_code) #sanity check to ensure that the site exists, should return 200\n",
    "#print (result.headers)\n",
    "src = result.content #saves the entire source code...\n",
    "#print (src)\n",
    "soup = BeautifulSoup (src, 'lxml') #converts source to beautifulsoup object/format/?\n",
    "links = soup.find_all(\"a\") #finds all the \"a\" tags (html links)\n",
    "#print (links)\n",
    "for link in links:\n",
    "    if \"About\" in link.text:\n",
    "        print (link)\n",
    "        print (link.attrs['href'])\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6155092b-cec6-4a3c-9ae6-cf1c99b159f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-89b67ac9dd94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.whitehouse.gov/briefings-statements/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#URL may change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'src' is not defined"
     ]
    }
   ],
   "source": [
    "#...\n",
    "#Purpose: (Tutorial) To import only links from whitehouse briefing-room\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "result = requests.get(\"https://www.whitehouse.gov/briefings-statements/\") #URL may change\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "urls = []\n",
    "for h2_tag in soup.find_all('h2'):\n",
    "    a_tag = h2_tag.find('a')\n",
    "    #print (h2_tag)\n",
    "    #if \"a \" in h2_tag.text:\n",
    "    #   print (f\"HERE!: {h2_tag}\")\n",
    "    #   urls.append(h2_tag.attrs['a']) #original code doesn't work because of new h2 tag w/o a link near title\n",
    "    #print (f\"THE A_TAG: {a_tag}\")\n",
    "    if a_tag != None: #this is NECESSARY for the H2 tags w/o an a_tag...\n",
    "    #        print (\"this is not a none!\")\n",
    "            urls.append(a_tag.attrs['href'])\n",
    "            print (a_tag.string)\n",
    "print(urls)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7f66e5-91f1-47ae-8d3b-cfa0b8644ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b another-attribute=\"1\" id=\"verybold\">Test 2</b>\n",
      "<b another-attribute=\"1\" id=\"verybold\">This is another string</b>\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "#Purpose: (Tutorial) To manipulate the objects obtained through beautifulsoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "<p class=\"story\">Once upon a time there were three little sisters; their names:\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "<p class=\"story\">...</p>\n",
    "<b class=\"boldest\">Extremely bold</b>\n",
    "<blockquote class=\"boldest\">Extremely bold</blockquote>\n",
    "<b id=\"1\">Test 1</b>\n",
    "<b another-attribute=\"1\" id=\"verybold\">Test 2</b>\n",
    "\"\"\"\n",
    "\n",
    "with open('index.html', 'w') as f:\n",
    "    f.write(html_doc)\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "#print (soup)\n",
    "#print (soup.prettify()) #prettify's the code (fully indented), but very uncompressed\n",
    "#print (soup.b) # prints the first <b /> tag\n",
    "#print (soup.p) # prints the first <p /> tag ---same as print (soup.find('b'))\n",
    "#print (soup.find_all('b')) # prints the first <b /> tag\n",
    "\n",
    "#can alter the name from <b> to <blockquote> - how to write it back into file?\n",
    "#tag = soup.b\n",
    "#print(tag)\n",
    "#tag.name = \"blockquote\"\n",
    "#print(tag)\n",
    "\n",
    "#**Attributes**\n",
    "#tag = soup.find_all('b')[2]\n",
    "#tag = soup.find_all('b')[3]\n",
    "#print (tag)\n",
    "#print (tag['id'])\n",
    "#print (tag['another-attribute'])\n",
    "#print (type(tag.attrs)) #returns a dictionry of all the attributes\n",
    "#tag ['another-attribute'] = 'a' #change the attribute\n",
    "#del tag['id'] # can delete attributes by specification\n",
    "#del tag['another-attribute']\n",
    "#print (tag)\n",
    "\n",
    "#**Naviagable String**\n",
    "tag = soup.find_all('b')[-1]\n",
    "print(tag)\n",
    "#print (tag.string) #extracts the string that is between the tags\n",
    "tag.string.replace_with(\"This is another string\") #can alter the displayable text\n",
    "print (tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36682bb-25c0-40f2-80a1-ed8d4b7cc840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Look in the children of this PageElement and find all\n",
       "PageElements that match the given criteria.\n",
       "\n",
       "All find_* methods take a common set of arguments. See the online\n",
       "documentation for detailed explanations.\n",
       "\n",
       ":param name: A filter on tag name.\n",
       ":param attrs: A dictionary of filters on attribute values.\n",
       ":param recursive: If this is True, find_all() will perform a\n",
       "    recursive search of this PageElement's children. Otherwise,\n",
       "    only the direct children will be considered.\n",
       ":param limit: Stop looking after finding this many results.\n",
       ":kwargs: A dictionary of filters on attribute values.\n",
       ":return: A ResultSet of PageElements.\n",
       ":rtype: bs4.element.ResultSet\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\envs\\basev2\\lib\\site-packages\\bs4\\element.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup.find_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97e6af-df21-40ad-b836-24dde6d8eb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
